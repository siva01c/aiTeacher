{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Children's Handwriting\n",
    "\n",
    "This Jupyter notebook explores methods for accurately reading children's handwriting while preserving all errors without any autocorrection. The goal is to identify and analyze mistakes in handwriting to support learning and improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image#\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocess_image() function converts the source image to a grayscale format and saves it as preprocessed_image.png. This step prepares the image for further analysis by enhancing contrast and reducing noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing with better noise reduction\n",
    "    \"\"\"\n",
    "    # Read image using opencv\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply bilateral filter to reduce noise while preserving edges\n",
    "    denoised = cv2.bilateralFilter(gray, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        enhanced,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        23,  # block size\n",
    "        8   # C constant subtracted from the mean or weighted sum\n",
    "    )\n",
    "    \n",
    "    # Remove small noise using morphological operations\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    denoised = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Clean up isolated pixels\n",
    "    kernel_clean = np.ones((2,2), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(denoised, cv2.MORPH_CLOSE, kernel_clean)\n",
    "    \n",
    "    # Invert back to black text on white background\n",
    "    final = cv2.bitwise_not(cleaned)\n",
    "    \n",
    "    # One final pass of median blur to clean up any remaining specks\n",
    "    final = cv2.medianBlur(final, 3)\n",
    "    \n",
    "    # Write the processed image to disk\n",
    "    cv2.imwrite(\"files/preprocessed/preprocessed_image.png\", final)\n",
    "    \n",
    "    # Save debug image\n",
    "    debug_images = np.hstack([gray, enhanced, final])\n",
    "    cv2.imwrite(\"files/preprocessed/debug_preprocessing.png\", debug_images)\n",
    "    \n",
    "    return \"files/preprocessed/preprocessed_image.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Convert image to base64 string\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical Character Recognition - OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image \n",
    "image_path = \"files/source/text.jpg\"\n",
    "# image_path = \"files/source/text2.jpg\"\n",
    "# image_path = \"files/source/text3.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `preprocess_image` will create a greyscale image and store it in `/files/preprocessed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCD using OpenAI\n",
    "\n",
    "https://platform.openai.com/docs/guides/vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def perform_ocr_openai(image_path):\n",
    "    \"\"\"\n",
    "    Perform OCR using GPT-4 Vision\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        \n",
    "        # Encode the preprocessed image\n",
    "        base64_image = encode_image_to_base64(preprocessed_image)\n",
    "        \n",
    "        # Initialize OpenAI client\n",
    "        client = OpenAI()  # Make sure OPENAI_API_KEY is set in your environment\n",
    "        \n",
    "        # Create the API request\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # Updated model name\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"Transcribe the text from this image exactly as it appears, preserving all spelling mistakes. Return only the text without modifications, explanations, or formatting. If any letters are unclear, replace them with *.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=1000,\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        # Extract the text from the response\n",
    "        text = response.choices[0].message.content\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform OCR using OpenAI \n",
    "extracted_text = perform_ocr_openai(image_path)\n",
    "    \n",
    "print(\"Extracted Text:\")\n",
    "print(\"--------------\")\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCD using pytesseract\n",
    "\n",
    "https://pypi.org/project/pytesseract/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "def perform_ocr_pytesseract(image_path):\n",
    "    \"\"\"\n",
    "    Perform OCR on the preprocessed image with custom configuration\n",
    "    \"\"\"\n",
    "    # Preprocess the image\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    \n",
    "    try:\n",
    "        # Load the preprocessed image\n",
    "        img = Image.open(preprocessed_image)\n",
    "        \n",
    "        # Configure tesseract parameters\n",
    "        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,!? \"'\n",
    "        \n",
    "        # Extract text from image\n",
    "        text = pytesseract.image_to_string(\n",
    "            img,\n",
    "            lang='ces',\n",
    "            config=custom_config\n",
    "        )\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform OCR using pytesseract\n",
    "extracted_text = perform_ocr_pytesseract(image_path)\n",
    "    \n",
    "print(\"Extracted Text:\")\n",
    "print(\"--------------\")\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCD using EasyOCR\n",
    "\n",
    "https://github.com/JaidedAI/EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "def perform_ocr_easyocr(image_path):\n",
    "    \"\"\"Perform OCR using EasyOCR.\"\"\"\n",
    "    reader = easyocr.Reader(['en', 'cs'], gpu=True)  # Supports English and Czech, use GPU\n",
    "    result = reader.readtext(image_path, detail=0)\n",
    "    return \" \".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform OCR using EasyOCR\n",
    "extracted_text = perform_ocr_easyocr(image_path)\n",
    "    \n",
    "print(\"Extracted Text:\")\n",
    "print(\"--------------\")\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCD using PaddleOCR\n",
    "\n",
    "https://paddlepaddle.github.io/PaddleOCR/main/en/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install paddleocr\n",
    "!pip install paddlepaddle-gpu\n",
    "\n",
    "# No GPU\n",
    "# !pip install paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "def perform_ocr_paddleocr(image_path):\n",
    "    \"\"\"Perform OCR using PaddleOCR.\"\"\"\n",
    "    ocr = PaddleOCR(lang='cs')  # Use 'cs' for Czech\n",
    "    result = ocr.ocr(image_path, cls=True)\n",
    "    extracted_text = \" \".join([word_info[1][0] for line in result for word_info in line])\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform OCR using PaddleOCR\n",
    "extracted_text = perform_ocr_paddleocr(image_path)\n",
    "    \n",
    "print(\"Extracted Text:\")\n",
    "print(\"--------------\")\n",
    "print(extracted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
